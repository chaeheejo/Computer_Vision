{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPac8lcpKumGIVPB9wU0CGi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1rnDQTMTC7Q",
        "outputId": "67fe35a1-5c75-44fb-eb30-e8bd680ff634"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvK4abSUTLWF",
        "outputId": "364da383-a987-4890-b6ea-5cadbd74c7e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ComputerVision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./drive/MyDrive/ComputerVision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQjnjZjLTXwQ",
        "outputId": "5f876689-e28c-4239-f1fa-638a104214dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ComputerVision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Dv13DsTgzi",
        "outputId": "0b7c860b-322e-43ad-e834-67492c5f7739"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_loader.py\tmodel.py       __pycache__  vgg.ipynb\n",
            "dataset\t\tproject.ipynb  train.py     weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.py\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(1536, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = x.reshape(-1, 1536)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "7EoziOHWUDMu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset.py\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "\n",
        "class eyes_dataset(Dataset):\n",
        "    def __init__(self, x_file_paths, y_file_path, transform=None):\n",
        "        self.x_files = x_file_paths\n",
        "        self.y_files = y_file_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_files[idx]\n",
        "        x = torch.from_numpy(x).float()\n",
        "\n",
        "        y = self.y_files[idx]\n",
        "        y = torch.from_numpy(y).float()\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_files)"
      ],
      "metadata": {
        "id": "wCpTqMllT6FX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "DGShJ6uGRcbf",
        "outputId": "39d5db8d-7a22-401f-9f6e-09678b211c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/50] train_loss: 0.42374 train_acc: 84.41250\n",
            "epoch: [2/50] train_loss: 0.11193 train_acc: 96.70000\n",
            "epoch: [3/50] train_loss: 0.08138 train_acc: 97.30000\n",
            "epoch: [4/50] train_loss: 0.04924 train_acc: 98.68750\n",
            "epoch: [5/50] train_loss: 0.04485 train_acc: 98.68750\n",
            "epoch: [6/50] train_loss: 0.02620 train_acc: 99.47500\n",
            "epoch: [7/50] train_loss: 0.01929 train_acc: 99.58750\n",
            "epoch: [8/50] train_loss: 0.01531 train_acc: 99.62500\n",
            "epoch: [9/50] train_loss: 0.01253 train_acc: 99.73750\n",
            "epoch: [10/50] train_loss: 0.00987 train_acc: 99.81250\n",
            "epoch: [11/50] train_loss: 0.01050 train_acc: 99.85000\n",
            "epoch: [12/50] train_loss: 0.00663 train_acc: 99.92500\n",
            "epoch: [13/50] train_loss: 0.03194 train_acc: 98.87500\n",
            "epoch: [14/50] train_loss: 0.00711 train_acc: 99.88750\n",
            "epoch: [15/50] train_loss: 0.00544 train_acc: 99.96250\n",
            "epoch: [16/50] train_loss: 0.00310 train_acc: 99.92500\n",
            "epoch: [17/50] train_loss: 0.00207 train_acc: 100.00000\n",
            "epoch: [18/50] train_loss: 0.00164 train_acc: 100.00000\n",
            "epoch: [19/50] train_loss: 0.00142 train_acc: 100.00000\n",
            "epoch: [20/50] train_loss: 0.00113 train_acc: 100.00000\n",
            "epoch: [21/50] train_loss: 0.00100 train_acc: 100.00000\n",
            "epoch: [22/50] train_loss: 0.00091 train_acc: 100.00000\n",
            "epoch: [23/50] train_loss: 0.00073 train_acc: 100.00000\n",
            "epoch: [24/50] train_loss: 0.00070 train_acc: 100.00000\n",
            "epoch: [25/50] train_loss: 0.00060 train_acc: 100.00000\n",
            "epoch: [26/50] train_loss: 0.00054 train_acc: 100.00000\n",
            "epoch: [27/50] train_loss: 0.00054 train_acc: 100.00000\n",
            "epoch: [28/50] train_loss: 0.00050 train_acc: 100.00000\n",
            "epoch: [29/50] train_loss: 0.00039 train_acc: 100.00000\n",
            "epoch: [30/50] train_loss: 0.00035 train_acc: 100.00000\n",
            "epoch: [31/50] train_loss: 0.00035 train_acc: 100.00000\n",
            "epoch: [32/50] train_loss: 0.00031 train_acc: 100.00000\n",
            "epoch: [33/50] train_loss: 0.00032 train_acc: 100.00000\n",
            "epoch: [34/50] train_loss: 0.00030 train_acc: 100.00000\n",
            "epoch: [35/50] train_loss: 0.00024 train_acc: 100.00000\n",
            "epoch: [36/50] train_loss: 0.00021 train_acc: 100.00000\n",
            "epoch: [37/50] train_loss: 0.00020 train_acc: 100.00000\n",
            "epoch: [38/50] train_loss: 0.00018 train_acc: 100.00000\n",
            "epoch: [39/50] train_loss: 0.00017 train_acc: 100.00000\n",
            "epoch: [40/50] train_loss: 0.00017 train_acc: 100.00000\n",
            "epoch: [41/50] train_loss: 0.00014 train_acc: 100.00000\n",
            "epoch: [42/50] train_loss: 0.00013 train_acc: 100.00000\n",
            "epoch: [43/50] train_loss: 0.00012 train_acc: 100.00000\n",
            "epoch: [44/50] train_loss: 0.00012 train_acc: 100.00000\n",
            "epoch: [45/50] train_loss: 0.00011 train_acc: 100.00000\n",
            "epoch: [46/50] train_loss: 0.00011 train_acc: 100.00000\n",
            "epoch: [47/50] train_loss: 0.00009 train_acc: 100.00000\n",
            "epoch: [48/50] train_loss: 0.00008 train_acc: 100.00000\n",
            "epoch: [49/50] train_loss: 0.00009 train_acc: 100.00000\n",
            "epoch: [50/50] train_loss: 0.00007 train_acc: 100.00000\n",
            "learning finish\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#train.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "x_train = np.load('./dataset/x_train.npy').astype(np.float32)  # (2586, 26, 34, 1)\n",
        "y_train = np.load('./dataset/y_train.npy').astype(np.float32)  # (2586, 1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])\n",
        "\n",
        "train_dataset = eyes_dataset(x_train, y_train, transform=train_transform)\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum / y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "\n",
        "    return acc\n",
        "\n",
        "PATH = 'weights/classifier_weights_iter_50.pt'\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        input_1, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        input = input_1.transpose(1, 3).transpose(2, 3)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += accuracy(outputs, labels)\n",
        "\n",
        "        if i % 80 == 79:\n",
        "            print('epoch: [%d/%d] train_loss: %.5f train_acc: %.5f' % (\n",
        "                epoch + 1, epochs, running_loss / 80, running_acc / 80))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"learning finish\")\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "PATH = 'weights/classifier_weights_iter_50.pt'\n",
        "\n",
        "x_test = np.load('./dataset/x_val.npy').astype(np.float32)  # (288, 26, 34, 1)\n",
        "y_test = np.load('./dataset/y_val.npy').astype(np.float32)  # (288, 1)\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_dataset = eyes_dataset(x_test, y_test, transform=test_transform)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "model = Net()\n",
        "model.to('cuda')\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "\n",
        "count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    total_acc = 0.0\n",
        "    acc = 0.0\n",
        "    for i, test_data in enumerate(test_dataloader, 0):\n",
        "        data, labels = test_data[0].to('cuda'), test_data[1].to('cuda')\n",
        "\n",
        "        data = data.transpose(1, 3).transpose(2, 3)\n",
        "\n",
        "        outputs = model(data)\n",
        "\n",
        "        acc = accuracy(outputs, labels)\n",
        "        total_acc += acc\n",
        "\n",
        "        count = i\n",
        "\n",
        "    print('avarage acc: %.5f' % (total_acc/count),'%')\n",
        "\n",
        "print('test finish!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1313NJuW9K7",
        "outputId": "035d5a82-e8a4-45ae-baa7-8bf9d4d7e3a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avarage acc: 99.65157 %\n",
            "test finish!\n"
          ]
        }
      ]
    }
  ]
}